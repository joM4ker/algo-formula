# RAG

## 背景

大语言模型的不足：

1. 知识的局限性：知识训练集源自公开数据集，内部数据、特定领域的知识无从学习。
2. 知识的滞后性：训练使用的公开数据集之后的新知识无从学习，且持续学习的成本较高。
3. 幻觉问题：模型底层基于数学计算，尤其对于大模型不擅长的知识范围的场景，可能会出现输出不符合事实。
4. 数据安全问题：

RAG是参数化模型和非参数化语料库的结合。

## RAG的挑战

1. 数据质量差导致检索效果差：语料库中如果存在错误信息，可能引导模型生成错误的输出。
2. 数据向量化的信息损失：语料向量化可能导致信息损失，因为文本的复杂多样性很难用有限的向量完全表达。
3. 语义搜索不准确：基于向量相似度的检索方式存在局限性，向量相似度不一定能真实反应语义相似度，向量空间中的噪声和异常值会干扰语义搜索的结果。TODO

## RAG范式

### Naive RAG

步骤：

1. 建立索引：离线数据清洗并分块，将分块后的知识通过embedding模型产出向量。
2. 检索：对于用户的问题使用相同的embedding模型，计算问题向量和语料向量之间的相似度，选择相似度最高的前k个块作为当前问题的增强上下文。
3. 生成：结合召回的语料快和历史上下文，生成结果。

挑战：

1. 检索质量低：向量中不能很好的突出核心信息，导致检索质量差。
2. 生成质量差：在未检索的知识的时候，生成思域问题的结果时，易出现幻觉问题。
3. 增强过程难：RAG和其他任务整合可能导致输出不连贯、复述检索内容等问题。

### Advanced RAG

基于Naive RAG，对知识检索做优化。

1. 检索前优化：

    a. Query改写：理解用户想表达的意图，把用户的原始问题转换成适合知识库检索的问题，提高检索精准度。

    b. Query路由：拆分不同类型或内容的知识库，Query先由大模型路由知识类型，提高检索效率

    c. Query扩展：通过增加元数据、上下文和相关术语扩展原始查询，提高检索的全面性和准确性，这样可以覆盖更多的潜在语料

2. 检索优化：

    a. 微调embedding模型

    b. 动态embedding根据单词的上下文结果不同，静态embedding对每个单词使用单一向量

    c. 混合搜索：结合向量搜索和关键字搜索

3. 检索后优化：

    a. 提示词压缩：删除无关内容，突出重要上下文，减少提示词长度

    b. 语料Rerank：基于精排模型重排检索出的语料

### Modular RAG

新增模块：

1. Search模块：适应特定场景，利用大模型生成代码或查询语言，搜索数据源
2. Memory模块：支持多轮对话。
3. Fusion模块：将用户Query扩展为多个Query。包含对原始Query和扩展Query的并行检索、智能重排序、最佳搜索结果。
4. Routing模块：预定义Query路由，确定用户问题领域，对特定领域使用对应的检索方式。
5. Predict模块：直接通过大模型生成上下文以减少冗余和噪声

### Graph RAG

向量检索结合知识图谱

1. 增强复杂问题回答能力：解决传统RAG在跨文档、多条推理中的局限，支持全局主题分析和局部细节检索

### Agentic RAG

通过引入Agent的自主决策能力，使系统从 被动检索-生成 流程升级为具备 主动规划、多步骤推理和工具调用 的智能体。其本质是Agent能力与传统RAG架构的融合，旨在解决复杂场景下传统RAG的局限性

核心功能可归纳为以下方面：

1. 动态任务规划：根据查询复杂度自主规划检索路径（如多跳检索、查询改写）
2. 多工具协同调用：灵活调用外部工具（如向量数据库、网络搜索、API、代码执行器）补充信息
3. 多代理协作（高级架构）：

    a. 单代理架构：一个代理协调多个工具。
    b. 多代理架构：顶层Agent协调多个文档代理Agent，分别处理不同文档或子任务，实现跨文档推理与全局总结

4. 结果评估与优化：对检索内容进行验证，通过反思（ReAct）机制优化输出质量
5. 复杂场景适应：适用于企业知识管理、智能客服、科研分析等需多源数据整合的领域

## 优化策略

### 知识加工生成

#### 拆分策略

1. 固定大小
2. 分隔符
3. 递归分割：多个分隔符，优先级从前到后依次分割。如果前一次分割后依然超过最大长度，这继续后一个分割符分割。如果按所有分割符分割后依然有超过最大长度的片段，则按最大长度拆分。同时引入滑动窗口重叠的方式，缓解上下文语义不连贯的问题。
4. 按token数
5. 特定文本格式
6. 语义分割

#### Embedding

高维度：

优点：

1. 高维度提供了更多的编码语义的空间
2. 更好地处理专业领域知识，利用高维度学习和区分复杂概念

缺点：

1. 存储成本增加
2. 计算成本增加，检索时耗时可能更大
3. 在非常高的维度空间中，向量距离之间的差别不大，对于基于距离的相似度计算方式，理论上存在维度灾难。

低维度：

优点：

1. 存储成本低
2. 计算速度快，检索延迟低
3. 学习到的知识更具有泛化性

缺点：

1. 信息缺失，低维度向量不能容纳复杂的寓意信息

RAG的Embedding过程

1. 输入文档片段
2. 通过分词器进行分词
3. 通过基础模型，对每个token生成一个上下文相关的向量
4. 池化：基于池化策略，从一系列token中得到一个能代表整段文本的单一向量

> 平均池化：所有token向量按维度取平均值
> CLSToken池化：通过基础模型前，在输入序列开头增加一个特殊的`Classification Token`，模型计算后，这个token被认为聚合了整个序列的语义，作为句子的表示

### 评估

#### 流程

1. 准备阶段：测试数据集构建需覆盖多样化的Query类型（事实型、推理型、多跳查询）和复杂度分布
2. 检索组件评估：核心指标包括

    a. 上下文相关性：通过LLM判断器计算检索片段与查询的相关句占比

    b. 召回率：验证关键信息是否被检索到，公式：Recall = 相关片段数/总相关片段数

    c. 工具要求：需支持混合检索（向量+关键词）和重排序（reranker）策略验证 。
3. 生成组件评估：关键维度包括

    a. 忠实度（Faithfulness）：检测生成内容与上下文的矛盾，计算方法：F=被上下文支持的声明数/总声明数

    b. 答案相关性（Answer Relevance）：通过LLM评估生成答案与查询的语义匹配度

4. 系统级集成评估

    a. 复合指标：RAG三元组（Query, Context, Answer）的协同评分，权重需按业务需求调整
    b. 失败分析：对低分样本进行归因（检索缺失/生成幻觉），建立改进闭环

5. 持续监控优化：部署后需监控生产环境指标（如P99延迟、错误率），定期进行A/B测试
